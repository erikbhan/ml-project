{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# imports\n",
    "from math import sqrt, log\n",
    "import gym\n",
    "import copy\n",
    "import numpy as np\n",
    "from gym_go.gogame import areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "UCB_C = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Three Search\n",
    "\n",
    "1. Selection\n",
    "    - Taverse the tree to find greatest UCB-score\n",
    "2. Expansion\n",
    "    - If the selected leaf node has been visited before expand by adding weighted game action\n",
    "3. Rollout\n",
    "    - Simulate the game until end-condition from the expanded leaf\n",
    "4. Back-propagation\n",
    "    - Updating the value of each ancestor node of the expanded leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legal_move(env):\n",
    "    board_shape = env.state().shape[1:]\n",
    "    pass_id = np.prod(board_shape)\n",
    "    action = env.action_space.sample() # pick random action\n",
    "    action2d = action // board_shape[0], action % board_shape[1], action\n",
    "    while action2d[2] != pass_id and env.state()[3, action2d[0], action2d[1]] == 1:\n",
    "        action = env.action_space.sample() # pick random action\n",
    "        action2d = action // board_shape[0], action % board_shape[1], action\n",
    "    return action2d[2]\n",
    "\n",
    "def do_best_action_for_each_turn(env, colour):\n",
    "    if env.done:\n",
    "        return\n",
    "    board_shape = env.state().shape[1:]\n",
    "    pass_id = np.prod(board_shape)\n",
    "\n",
    "    best_move = pass_id\n",
    "    black_area, white_area = areas(env.state())\n",
    "    for action in range(0, pass_id + 1):\n",
    "        action2d = action // board_shape[0], action % board_shape[1]\n",
    "        if action == pass_id or env.state()[3, action2d[0], action2d[1]] == 0:\n",
    "            copy_env : gym.Env = copy.deepcopy(env)\n",
    "            copy_env.step(action)\n",
    "            step_black_area, step_white_area = areas(copy_env.state())\n",
    "            if colour == \"white\" and step_black_area > black_area:\n",
    "                black_area = step_black_area\n",
    "                best_move = action\n",
    "            if colour == \"black\" and step_white_area > white_area:\n",
    "                white_area = step_white_area\n",
    "                best_move = action\n",
    "    env.step(best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, env, parent):\n",
    "        self.orgional_env : gym.Env = copy.deepcopy(env) # Copy of starting env for printing game later\n",
    "        self.env : gym.Env = env # This env will be altered by the other player\n",
    "        self.value : int = 0 # Value estimate\n",
    "        self.trials : int = 0 # Number of trials for this node\n",
    "        self.parent : Node = parent # Parent node of this node\n",
    "        self.children : list[Node] = [] # List of children of this node\n",
    "    \n",
    "    # calculate a Upper Confidence Bound\n",
    "    def ucb(self, total_trials):\n",
    "        return self.value + ( UCB_C * sqrt(log(total_trials) / self.trials) )\n",
    "    \n",
    "    # Add a new node to a leaf node\n",
    "    def expansion(self):\n",
    "        if self.env.done:\n",
    "            return\n",
    "        board_shape = self.env.state().shape[1:]\n",
    "        pass_id = np.prod(board_shape)\n",
    "        for action in range(0, pass_id + 1):\n",
    "            action2d = action // board_shape[0], action % board_shape[1]\n",
    "            if action == pass_id or self.env.state()[3, action2d[0], action2d[1]] == 0:\n",
    "                child_env = copy.deepcopy(self.env)\n",
    "                child_env.step(action)\n",
    "                self.children.append(Node(child_env, self))\n",
    "\n",
    "    # Simulate game from current move until end-condition returning the score\n",
    "    def rollout(self):\n",
    "        if self.env.done:\n",
    "            return self.env.reward()\n",
    "        \n",
    "        rollout_env = copy.deepcopy(self.env)\n",
    "        rollout_result = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            random_action = get_legal_move(rollout_env)\n",
    "            _, reward, done, _ = rollout_env.step(random_action)\n",
    "            rollout_result += reward\n",
    "        return rollout_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monte_Carlo_Tree_Search():\n",
    "    def __init__(self, colour, do_other_players_turn):\n",
    "        self.env = gym.make('gym_go:go-v0', size=3, komi=0, reward_method='heuristic')\n",
    "        self.env.reset()\n",
    "        self.number_of_trials : int = 0\n",
    "        self.root = Node(self.env, None)\n",
    "        self.colour = colour\n",
    "        self.do_other_players_turn = do_other_players_turn\n",
    "    \n",
    "    # Update scores of all parent nodes after rollout\n",
    "    def back_propagation(self, rollout_node: Node, rollout_result):\n",
    "        current_node = rollout_node\n",
    "        while current_node != None:\n",
    "            current_node.trials += 1\n",
    "            if self.colour == \"white\":\n",
    "                current_node.value += -rollout_result\n",
    "            else: \n",
    "                current_node.value += rollout_result\n",
    "            current_node = current_node.parent\n",
    "        self.number_of_trials += 1\n",
    "    \n",
    "    # find and return the leaf node with the highest UCB-score \n",
    "    def selection(self, starting_node: Node):\n",
    "        selected_child = starting_node\n",
    "        current_node = starting_node\n",
    "        while len(current_node.children) > 0:\n",
    "            selected_child = current_node.children[0]\n",
    "            current_best_ucb = 0\n",
    "            for child in current_node.children:\n",
    "                if child.trials == 0:\n",
    "                    return child\n",
    "                \n",
    "                if current_node.children.index(child) == 0:\n",
    "                    current_best_ucb = current_node.children[0].ucb(self.number_of_trials)\n",
    "\n",
    "                child_ucb = child.ucb(self.number_of_trials)\n",
    "                if child_ucb > current_best_ucb:\n",
    "                    selected_child = child\n",
    "                    current_best_ucb = child_ucb\n",
    "                    \n",
    "            current_node = selected_child\n",
    "            \n",
    "        return selected_child\n",
    "\n",
    "    def run(self):\n",
    "        if self.colour == \"white\":\n",
    "            self.do_other_players_turn(self.root.env, self.colour)\n",
    "        selected_node = self.root\n",
    "        selected_node.expansion()\n",
    "        selected_node = self.root.children[0]\n",
    "\n",
    "        run = 0\n",
    "        while not selected_node.env.done:\n",
    "            selected_node = self.selection(self.root)\n",
    "            # print(\"Node selected\")\n",
    "            if selected_node.trials > 0:\n",
    "                self.do_other_players_turn(selected_node.env, self.colour)\n",
    "                selected_node.expansion()\n",
    "                if len(selected_node.children) > 0:\n",
    "                    selected_node = selected_node.children[0]\n",
    "                # print(\"Node expanded\")\n",
    "\n",
    "            if selected_node.env.done:\n",
    "                self.back_propagation(selected_node, selected_node.env.reward())\n",
    "                self.selection(self.root)\n",
    "                run += 1\n",
    "                # print(\"Backpropagation complete, reward: \", selected_node.env.reward())\n",
    "                continue\n",
    "\n",
    "            rollout_result = selected_node.rollout()\n",
    "            # print(\"Rollout complete\")\n",
    "            self.back_propagation(selected_node, rollout_result)\n",
    "            # print(\"Backpropagation complete, reward: \", rollout_result)\n",
    "            black_area, white_area = areas(selected_node.env.state())\n",
    "            # print(\"Itteration:\", run, \"Black area:\", black_area, \"White area:\", white_area)\n",
    "            run += 1\n",
    "            if run > 60:\n",
    "                return self.selection(self.root)\n",
    "        return selected_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Monte_Carlo_Tree_Search(\"black\", do_best_action_for_each_turn)\n",
    "best_node = model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n",
      "\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: BLACK, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 0, White Area: 0\n",
      "\n",
      "\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─○\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═╤═╗\n",
      "1\t╟─┼─○\n",
      "2\t╚═╧═╝\n",
      "\tTurn: BLACK, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 1, White Area: 1\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═╤═╗\n",
      "1\t╟─┼─○\n",
      "2\t╚═○═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 3, White Area: 1\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═●═╗\n",
      "1\t╟─┼─○\n",
      "2\t╚═○═╝\n",
      "\tTurn: BLACK, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 3, White Area: 2\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═●═○\n",
      "1\t╟─┼─○\n",
      "2\t╚═○═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 4, White Area: 2\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═●═○\n",
      "1\t●─┼─○\n",
      "2\t╚═○═╝\n",
      "\tTurn: BLACK, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 4, White Area: 3\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═●═○\n",
      "1\t●─┼─○\n",
      "2\t○═○═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 5, White Area: 3\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═●═○\n",
      "1\t●─┼─○\n",
      "2\t○═○═╝\n",
      "\tTurn: BLACK, Game State (ONGOING|PASSED|END): PASSED\n",
      "\tBlack Area: 5, White Area: 3\n",
      "\n",
      "\t0 1 2 \n",
      "0\t●═●═○\n",
      "1\t●─┼─○\n",
      "2\t○═○═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): END\n",
      "\tBlack Area: 5, White Area: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_game : list[Node] = []\n",
    "current_node = best_node\n",
    "while current_node != None:\n",
    "    best_game.append(current_node)\n",
    "    current_node = current_node.parent\n",
    "\n",
    "for node in reversed(best_game):\n",
    "    if node.parent != None and (best_game.index(node) != 0):\n",
    "        node.orgional_env.render()\n",
    "    node.env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ml-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c48e9d02fd8b77616e4eb406249914dfd12f6a6048a8be47690e9d71e734832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
