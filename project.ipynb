{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Factor out classes into .py-files to make notebook more concise\n",
    "- Find package versions where we don't need to filter warnings (older packages)\n",
    "- Set up pseudocode for the tournament;\n",
    "    - players, saving models, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.CNN import CNN\n",
    "from src.MCTS import Monte_Carlo_Tree_Search\n",
    "\n",
    "from gym_go.gogame import random_action\n",
    "from copy import deepcopy\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BOARD_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game_no_render(mcts : Monte_Carlo_Tree_Search, go_env: gym.Env):\n",
    "    go_env.reset()\n",
    "    done = go_env.done\n",
    "    turn_nr = 0\n",
    "    while not done:\n",
    "        action = random_action(go_env.state())\n",
    "        _, _, done, _ = go_env.step(action)\n",
    "\n",
    "        if done:\n",
    "            continue\n",
    "\n",
    "        node = mcts.get_move_from_env(go_env)\n",
    "        _, _, done, _ = go_env.step(node.action)\n",
    "        turn_nr += 1\n",
    "        if turn_nr > 300:\n",
    "            break\n",
    "    \n",
    "    return go_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "Black won!\n",
      "White won!\n",
      "White won!\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    mcts_test = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\n",
    "    env = play_game_no_render(mcts_test, deepcopy(mcts_test.env))\n",
    "    if not env.done:\n",
    "        print(\"Game stopped after 300 turns: \\nIt was resigned and is a draw.\")\n",
    "        continue\n",
    "\n",
    "    if env.reward() < 0:\n",
    "        print(\"White won!\")\n",
    "    if env.reward() > 0:\n",
    "        print(\"Black won!\")\n",
    "    if env.reward() == 0:\n",
    "        print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, lr, momentum):\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     for epoch in range(10):\n",
    "#         mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model) # new tree\n",
    "#         mcts.run_game() # run a single game to completion\n",
    "#         x, y = mcts.get_tree_data() # get data\n",
    "#         running_loss = .0 \n",
    "#         for i in range(len(x)):\n",
    "#             inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "#             labels = F.softmax(labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item()\n",
    "\n",
    "#             if i % 10 == 9:\n",
    "#                 print(f'[{epoch:3d}, {i + 1:3d}] loss: {running_loss / 10:.5f}')\n",
    "#                 running_loss = 0.0\n",
    "\n",
    "# def train(n_games=1000):\n",
    "\n",
    "#     model = CNN()\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#     all_x, all_y = [], []\n",
    "\n",
    "#     # Simulate N games\n",
    "#     for _ in range(n_games):\n",
    "#         mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model)\n",
    "#         mcts.run(10_000)\n",
    "#         x, y = mcts.get_tree_data()\n",
    "\n",
    "#         for i in range(len(x)):\n",
    "#             inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "#             labels = F.softmax(labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             all_x.append(x[i])\n",
    "#             all_y.append(y[i])\n",
    "        \n",
    "#         # After training, check accuracy against previous data\n",
    "#         acc_values.append(model.avg_accuracy(all_x, all_y).item())\n",
    "#         loss_values.append(game_loss/len(x))\n",
    "\n",
    "#     print(f'''Finished running {n_games} games\n",
    "#     Time..............: {total_time}\n",
    "#     Avg. time per game: {total_time/n_games}''')\n",
    "#     return model, loss_values, acc_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss_values, acc_values = train(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS and CNN combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_game(x, y, model):\n",
    "    mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model)\n",
    "    mcts.run_game()\n",
    "    # mcts.run(10_000)\n",
    "    a, b = mcts.get_tree_data()\n",
    "    x.append(a)\n",
    "    y.append(b)\n",
    "\n",
    "def generate_games(x, y, n_games, model):\n",
    "    print(f\"Generating {n_games} games\")\n",
    "    Parallel(n_jobs=10)(delayed(generate_game)(x, y, model) for _ in range(1, n_games))\n",
    "\n",
    "def train_model(model, criterion, optimizer, x, y):\n",
    "    print(\"Training model\")\n",
    "    for i in range(len(x)):\n",
    "        inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "        labels = F.softmax(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000 games\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'render_modes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\Alida\\AppData\\Local\\Temp\\ipykernel_11116\\3647033732.py\", line 2, in generate_game\n  File \"c:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\src\\MCTS.py\", line 73, in __init__\n    self.env : gym.Env = gym.make('gym_go:go-v0', size=size, reward_method='heuristic')\n  File \"c:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\gym\\envs\\registration.py\", line 625, in make\n    render_modes = env_creator.metadata[\"render_modes\"]\nKeyError: 'render_modes'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m x, y \u001b[39m=\u001b[39m [], []\n\u001b[1;32m----> 2\u001b[0m generate_games(x, y, \u001b[39m1000\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m      4\u001b[0m model \u001b[39m=\u001b[39m CNN()\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mgenerate_games\u001b[1;34m(x, y, n_games, model)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_games\u001b[39m(x, y, n_games, model):\n\u001b[0;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating \u001b[39m\u001b[39m{\u001b[39;00mn_games\u001b[39m}\u001b[39;00m\u001b[39m games\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)(delayed(generate_game)(x, y, model) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m, n_games))\n",
      "File \u001b[1;32mc:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Alida\\Documents\\Skole\\Dataingenior5.semester\\Maskinlering\\ml-project\\ml-venv\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'render_modes'"
     ]
    }
   ],
   "source": [
    "x, y = [], []\n",
    "generate_games(x, y, 1000, None)\n",
    "\n",
    "model = CNN()\n",
    "model.to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train_model(model, criterion, optimizer, x, y)\n",
    "\n",
    "print(\"Exporting model\")\n",
    "torch.save(model.state_dict(), f\"models/only-mcts.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000 games\n",
      "Training model\n",
      "Generating 1000 games\n",
      "Training model\n",
      "Generating 1000 games\n",
      "Training model\n",
      "Generating 1000 games\n",
      "Training model\n"
     ]
    }
   ],
   "source": [
    "# model = CNN()\n",
    "# model.load_state_dict(torch.load(\"models/only-mcts.pth\"))\n",
    "# model.eval()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "for i in range(2, 6):\n",
    "    x, y = [], []\n",
    "    generate_games(x, y, 1000, model)\n",
    "    train_model(model, criterion, optimizer, x, y)\n",
    "    torch.save(model.state_dict(), f\"models/{i}-times.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ml-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c48e9d02fd8b77616e4eb406249914dfd12f6a6048a8be47690e9d71e734832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
