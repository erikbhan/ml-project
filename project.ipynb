{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# imports\n",
    "from math import sqrt, log\n",
    "import gym\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "UCB_C = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Three Search\n",
    "\n",
    "1. Selection\n",
    "    - Taverse the tree to find greatest UCB-score\n",
    "2. Expansion\n",
    "    - If the selected leaf node has been visited before expand by adding weighted game action\n",
    "3. Rollout\n",
    "    - Simulate the game until end-condition from the expanded leaf\n",
    "4. Back-propagation\n",
    "    - Updating the value of each ancestor node of the expanded leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legal_move(env):\n",
    "    board_shape = env.state().shape[1:]\n",
    "    pass_id = np.prod(board_shape)\n",
    "    action = env.action_space.sample() # pick random action\n",
    "    action2d = action // board_shape[0], action % board_shape[1], action\n",
    "    while action2d[2] != pass_id and env.state()[3, action2d[0], action2d[1]] == 1:\n",
    "        action = env.action_space.sample() # pick random action\n",
    "        action2d = action // board_shape[0], action % board_shape[1], action\n",
    "    return action2d[2]\n",
    "\n",
    "def do_other_players_turn(env):\n",
    "    if env.done:\n",
    "        return\n",
    "    board_shape = env.state().shape[1:]\n",
    "    pass_id = np.prod(board_shape)\n",
    "\n",
    "    best_move = pass_id\n",
    "    reward = env.reward()\n",
    "    for action in range(0, pass_id + 1):\n",
    "        action2d = action // board_shape[0], action % board_shape[1]\n",
    "        if action == pass_id or env.state()[3, action2d[0], action2d[1]] == 0:\n",
    "            copy_env = copy.deepcopy(env)\n",
    "            _, step_reward, _, _  = copy_env.step(action)\n",
    "            if step_reward < reward:\n",
    "                reward = step_reward\n",
    "                best_move = action\n",
    "\n",
    "    env.step(best_move)\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, env, parent):\n",
    "        self.env : gym.Env = env\n",
    "        self.value : int = 0 # Value estimate\n",
    "        self.trials : int = 0 # Number of trials for this node\n",
    "        self.parent : Node = parent # Parent node of this node\n",
    "        self.children : list[Node] = [] # List of children of this node\n",
    "    \n",
    "    # calculate a Upper Confidence Bound\n",
    "    def ucb(self, total_trials):\n",
    "        return self.value + ( UCB_C * sqrt(log(total_trials) / self.trials) )\n",
    "    \n",
    "    # Add a new node to a leaf node\n",
    "    def expansion(self):\n",
    "        if self.env.done:\n",
    "            return\n",
    "        print(\"Expanding node\")\n",
    "        board_shape = self.env.state().shape[1:]\n",
    "        pass_id = np.prod(board_shape)\n",
    "        for action in range(0, pass_id + 1):\n",
    "            action2d = action // board_shape[0], action % board_shape[1]\n",
    "            if action == pass_id or self.env.state()[3, action2d[0], action2d[1]] == 0:\n",
    "                child_env = copy.deepcopy(self.env)\n",
    "                child_env.step(action)\n",
    "                self.children.append(Node(child_env, self))\n",
    "        for child in self.children:\n",
    "            print(vars(child))\n",
    "\n",
    "    # Simulate game from current move until end-condition returning the score\n",
    "    def rollout(self):\n",
    "        if self.env.done:\n",
    "            return self.env.reward()\n",
    "        \n",
    "        rollout_env = copy.deepcopy(self.env)\n",
    "        rollout_result = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            random_action = get_legal_move(rollout_env)\n",
    "            _, reward, done, _ = rollout_env.step(random_action)\n",
    "            rollout_result += reward\n",
    "        return rollout_result\n",
    "\n",
    "class Monte_Carlo_Tree_Search():\n",
    "    def __init__(self, colour):\n",
    "        self.env = gym.make('gym_go:go-v0', size=3, komi=0, reward_method='heuristic')\n",
    "        self.env.reset()\n",
    "        self.number_of_trials : int = 0\n",
    "        self.root = Node(self.env, None)\n",
    "        self.colour = colour\n",
    "    \n",
    "    # Update scores of all parent nodes after rollout\n",
    "    def back_propagation(self, rollout_node: Node, rollout_result):\n",
    "        current_node = rollout_node\n",
    "        while current_node != None:\n",
    "            current_node.trials += 1\n",
    "            if self.colour == \"white\":\n",
    "                current_node.value += -rollout_result\n",
    "            else: \n",
    "                current_node.value += rollout_result\n",
    "            current_node = current_node.parent\n",
    "        self.number_of_trials += 1\n",
    "    \n",
    "    # find and return the leaf node with the highest UCB-score \n",
    "    def selection(self, starting_node: Node):\n",
    "        selected_child = starting_node\n",
    "        current_best_ucb = 0\n",
    "        current_node = starting_node\n",
    "        while len(current_node.children) > 0:\n",
    "            for child in current_node.children:\n",
    "                if child.trials == 0:\n",
    "                    return child\n",
    "                if child.ucb(self.number_of_trials) > current_best_ucb:\n",
    "                    selected_child = child\n",
    "                    print(\"New best child\")\n",
    "            current_node = selected_child\n",
    "            current_best_ucb = 0\n",
    "            \n",
    "        return selected_child\n",
    "\n",
    "    def run(self):\n",
    "        if self.colour == \"white\":\n",
    "            do_other_players_turn(self.root.env)\n",
    "        selected_node = self.root\n",
    "        selected_node.expansion()\n",
    "        selected_node = self.root.children[0]\n",
    "\n",
    "        run = 0\n",
    "        while not selected_node.env.done:\n",
    "            print(run)\n",
    "            selected_node = self.selection(self.root)\n",
    "\n",
    "            if selected_node.trials > 0:\n",
    "                selected_node.expansion()\n",
    "                selected_node = selected_node.children[0]\n",
    "            else:\n",
    "                do_other_players_turn(selected_node.env)\n",
    "                if selected_node.env.done:\n",
    "                    print(\"other player ended the game on their turn\")\n",
    "                    self.back_propagation(selected_node, selected_node.env.reward())\n",
    "                    self.selection(self.root)\n",
    "                    run += 1\n",
    "                    continue\n",
    "\n",
    "            rollout_result = selected_node.rollout()\n",
    "            self.back_propagation(selected_node, rollout_result)\n",
    "\n",
    "            run += 1\n",
    "            if run > 1000:\n",
    "                return self.selection(self.root)\n",
    "        return selected_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding node\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t○═╤═╗\n",
      "1\t╟─┼─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═○═╗\n",
      "1\t╟─┼─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═○\n",
      "1\t╟─┼─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t○─┼─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─○─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─○\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─╢\n",
      "2\t○═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─╢\n",
      "2\t╚═○═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─╢\n",
      "2\t╚═╧═○\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 9, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "{'env': <OrderEnforcing<PassiveEnvChecker\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: WHITE, Game State (ONGOING|PASSED|END): PASSED\n",
      "\tBlack Area: 0, White Area: 0\n",
      ">>, 'value': 0, 'trials': 0, 'parent': <__main__.Node object at 0x0000028CE9830DC0>, 'children': []}\n",
      "\t0 1 2 \n",
      "0\t╔═╤═╗\n",
      "1\t╟─┼─╢\n",
      "2\t╚═╧═╝\n",
      "\tTurn: BLACK, Game State (ONGOING|PASSED|END): ONGOING\n",
      "\tBlack Area: 0, White Area: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Monte_Carlo_Tree_Search(\"black\")\n",
    "model.root.expansion()\n",
    "do_other_players_turn(model.root.children[0].env)\n",
    "model.root.env.render()\n",
    "# best_node = model.run()\n",
    "# print(\"Run complete\")\n",
    "# print(model.selection(model.root))\n",
    "\n",
    "# best_game = []\n",
    "# current_node = best_node\n",
    "# while current_node != None:\n",
    "#     best_game.append(current_node)\n",
    "#     current_node = current_node.parent\n",
    "\n",
    "# for node in reversed(best_game):\n",
    "#     node.env.render()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9603291928c829f89796b29b3829333c7cae232406f14762083705f04106de1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
