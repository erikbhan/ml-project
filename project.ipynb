{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the different models produced in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "from src.CNN import CNN\n",
    "from src.MCTS import Monte_Carlo_Tree_Search\n",
    "\n",
    "from gym_go.gogame import random_action, turn\n",
    "from copy import deepcopy\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BOARD_SIZE = 5\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing win rates for MCTS vs Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcts_black_random_white(mcts : Monte_Carlo_Tree_Search, go_env: gym.Env):\n",
    "    go_env.reset()\n",
    "    done = go_env.done\n",
    "    turn_nr = 0\n",
    "    while not done:\n",
    "        node = mcts.get_move_from_env(go_env)\n",
    "        _, _, done, _ = go_env.step(node.action)\n",
    "        turn_nr += 1\n",
    "\n",
    "        if done:\n",
    "            continue\n",
    "\n",
    "        action = random_action(go_env.state())\n",
    "        _, _, done, _ = go_env.step(action)\n",
    "\n",
    "        if turn_nr > 300:\n",
    "            break\n",
    "    \n",
    "    return go_env\n",
    "\n",
    "def random_black_mcts_white(mcts : Monte_Carlo_Tree_Search, go_env: gym.Env):\n",
    "    go_env.reset()\n",
    "    done = go_env.done\n",
    "    turn_nr = 0\n",
    "    while not done:\n",
    "        action = random_action(go_env.state())\n",
    "        _, _, done, _ = go_env.step(action)\n",
    "\n",
    "        if done:\n",
    "            continue\n",
    "\n",
    "        node = mcts.get_move_from_env(go_env)\n",
    "        _, _, done, _ = go_env.step(node.action)\n",
    "        turn_nr += 1\n",
    "        \n",
    "        if turn_nr > 300:\n",
    "            break\n",
    "    \n",
    "    return go_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate as black: 0.0 %\n",
      "Win rate as white: 90.0 %\n"
     ]
    }
   ],
   "source": [
    "def play_black_game():\n",
    "    mcts_test = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\n",
    "    env = mcts_black_random_white(mcts_test, deepcopy(mcts_test.env))\n",
    "    if env.reward() > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def play_white_game():\n",
    "    mcts_test = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\n",
    "    env = random_black_mcts_white(mcts_test, deepcopy(mcts_test.env))\n",
    "    if env.reward() < 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "games = 100\n",
    "\n",
    "mcts_black_wins = Parallel(n_jobs=4)(delayed(play_black_game)() for _ in range(games))\n",
    "print(\"Win rate as black:\", ((sum(mcts_black_wins) / games) * 100), \"%\")\n",
    "mcts_white_wins = Parallel(n_jobs=4)(delayed(play_white_game)() for _ in range(games))\n",
    "print(\"Win rate as white:\", ((sum(mcts_white_wins) / games) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Convolutional Neural Network vs random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNN(\n",
      "  (conv1): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
      "), CNN(\n",
      "  (conv1): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
      "), CNN(\n",
      "  (conv1): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
      "), CNN(\n",
      "  (conv1): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
      "), CNN(\n",
      "  (conv1): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=26, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "players = []\n",
    "for i in range(5):\n",
    "    player = CNN()\n",
    "    player.to(device)\n",
    "    player.load_state_dict(torch.load(f\"src/models/1000-games/{i}-times.pth\"))\n",
    "    players.append(player)\n",
    "print(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5372\\2422530990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplay_game_no_render\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gym_go:go-v0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBOARD_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkomi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'heuristic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Game stopped after 300 turns: \\nIt was resigned and is a draw.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5372\\2422530990.py\u001b[0m in \u001b[0;36mplay_game_no_render\u001b[1;34m(model, go_env)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgo_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml2\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml2\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mstep_returns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_step_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstep_to_new_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml2\\lib\\site-packages\\gym\\wrappers\\env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\erik\\gymgo\\gym_go\\envs\\go_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgogame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgogame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_ended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgame_ended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\erik\\gymgo\\gym_go\\envs\\go_env.py\u001b[0m in \u001b[0;36mreward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRewardMethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHEURISTIC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[0mblack_area\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhite_area\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgogame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mareas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[0marea_difference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblack_area\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwhite_area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mkomi_correction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marea_difference\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkomi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\erik\\gymgo\\gym_go\\gogame.py\u001b[0m in \u001b[0;36mareas\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_empty_areas\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mempty_area\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty_labels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[0mneighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempty_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[0mblack_claim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mwhite_claim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml2\\lib\\site-packages\\scipy\\ndimage\\morphology.py\u001b[0m in \u001b[0;36mbinary_dilation\u001b[1;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstructure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mstructure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_binary_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m     \u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[0mstructure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml2\\lib\\site-packages\\scipy\\ndimage\\morphology.py\u001b[0m in \u001b[0;36mgenerate_binary_structure\u001b[1;34m(rank, connectivity)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml2\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mindices\u001b[1;34m(dimensions, dtype, sparse)\u001b[0m\n\u001b[0;32m   1776\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m             \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def play_game_no_render(model : CNN, go_env: gym.Env):\n",
    "    go_env.reset()\n",
    "    done = go_env.done\n",
    "    turn_nr = 0\n",
    "    while not done:\n",
    "        action = random_action(go_env.state())\n",
    "        _, _, done, _ = go_env.step(action)\n",
    "\n",
    "        if done: break\n",
    "        weights = model.forward(go_env.state()).detach().cpu().numpy()\n",
    "        weights = weights*go_env.valid_moves()\n",
    "        _, _, done, _ = go_env.step(weights.argmax())\n",
    "\n",
    "        turn_nr += 1\n",
    "        if turn_nr > 300: break\n",
    "    return go_env\n",
    "\n",
    "model_wins = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    env = play_game_no_render(players[4], gym.make('gym_go:go-v0', size=BOARD_SIZE, komi=0, reward_method='heuristic'))\n",
    "    if not env.done:\n",
    "        print(\"Game stopped after 300 turns: \\nIt was resigned and is a draw.\")\n",
    "        continue\n",
    "\n",
    "    if env.reward() > 0: model_wins += 1\n",
    "    if env.reward() == 0: print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model won 16.400000000000002%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model won {(model_wins/1000)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model training levels vs each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # coding: utf-8\n",
    "\n",
    "# # ignore deprecation warnings ('safe' as long as we don't update packages)\n",
    "# from joblib import Parallel, delayed\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from src.CNN import CNN\n",
    "# from src.MCTS import Monte_Carlo_Tree_Search\n",
    "\n",
    "# BOARD_SIZE = 5\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def generate_game(x, y, model):\n",
    "#     mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model)\n",
    "#     # mcts.run_game()\n",
    "#     mcts.run(1000)\n",
    "#     a, b = mcts.get_tree_data()\n",
    "#     x.append(a)\n",
    "#     y.append(b)\n",
    "\n",
    "# def generate_games(x, y, n_games, model):\n",
    "#     print(f\"Generating {n_games} games\")\n",
    "#     Parallel(n_jobs=10)(delayed(generate_game)(x, y, model) for _ in range(1, n_games))\n",
    "\n",
    "# def train_model(model, criterion, optimizer, x, y):\n",
    "#     print(\"Training model\")\n",
    "#     for i in range(len(x)):\n",
    "#         inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "#         labels = F.softmax(labels)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# model = CNN()   \n",
    "# model.to(device=device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# for i in range(5):\n",
    "#     x, y = [], []\n",
    "#     if i == 0: generate_games(x, y, 10, None)\n",
    "#     else: generate_games(x, y, 10, model)\n",
    "#     train_model(model, criterion, optimizer, x, y)\n",
    "#     torch.save(model.state_dict(), f\"models/{i}-times.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # go_env.reset()\n",
    "    # done = go_env.done\n",
    "    # players = [model1, model2]\n",
    "    # while not done:\n",
    "    #     weights = model1.forward(go_env.state()).detach().cpu().numpy()\n",
    "    #     weights = weights*go_env.valid_moves()\n",
    "    #     _, _, done, _ = go_env.step(weights.argmax())\n",
    "    #     if done: continue\n",
    "\n",
    "    #     weights = model2.forward(go_env.state()).detach().cpu().numpy()\n",
    "    #     weights = weights*go_env.valid_moves()\n",
    "    #     _, _, done, _ = go_env.step(weights.argmax())\n",
    "    #     turn_nr += 1\n",
    "    #     if turn_nr > 300: break\n",
    "hundred_games = CNN()\n",
    "hundred_games.to(device)\n",
    "hundred_games.load_state_dict(torch.load(f\"100-games/0-times.pth\"))\n",
    "\n",
    "def play_model_vs_model_no_render(model1 : CNN, model2 : CNN, max_moves=300):\n",
    "        go_env = gym.make('gym_go:go-v0', size=BOARD_SIZE, komi=0, reward_method='heuristic')\n",
    "        go_env.reset()\n",
    "        \n",
    "        players = [model1, model2]\n",
    "        for _ in range(max_moves):\n",
    "            if go_env.done: break\n",
    "            for _ in players:\n",
    "                if go_env.done: break\n",
    "                # action = random_action(go_env.state())\n",
    "                # _, _, done, _ = go_env.step(action)\n",
    "                \n",
    "                weights = hundred_games.forward(go_env.state()).detach().cpu().numpy()\n",
    "                weights = weights*go_env.valid_moves()\n",
    "                go_env.step(weights.argmax())\n",
    "        return go_env.reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black wins: 0\n",
      "White wins: 1000\n",
      "Draws: 0\n"
     ]
    }
   ],
   "source": [
    "bwd = [0]*3\n",
    "for i in range(1000):\n",
    "    reward = play_model_vs_model_no_render(players[4], players[0])\n",
    "    if reward > 0: bwd[0] += 1\n",
    "    if reward < 0: bwd[1] += 1\n",
    "    else: bwd[2] += 1\n",
    "print(f\"Black wins: {bwd[0]}\\nWhite wins: {bwd[1]}\\nDraws: {bwd[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tournament:  0\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'OrderEnforcing' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m game_number \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTournament: \u001b[39m\u001b[39m\"\u001b[39m, game_number, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     play_tournament(wins, draws, games_played, b_w)\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 17\u001b[0m in \u001b[0;36mplay_tournament\u001b[1;34m(wins, draws, games_played, b_w)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m p1, p2 \u001b[39m=\u001b[39m players[player1_index], players[player2_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# print(f\"  Starting a game between {player1_index} and {player2_index}\", end=\"\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# start = time.time()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m go_env \u001b[39m=\u001b[39m play_model_vs_model_no_render(p1, p2, gym\u001b[39m.\u001b[39;49mmake(\u001b[39m'\u001b[39;49m\u001b[39mgym_go:go-v0\u001b[39;49m\u001b[39m'\u001b[39;49m, size\u001b[39m=\u001b[39;49mBOARD_SIZE, komi\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, reward_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mheuristic\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# stop = time.time()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m go_env\u001b[39m.\u001b[39mreward() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 17\u001b[0m in \u001b[0;36mplay_model_vs_model_no_render\u001b[1;34m(model1, model2, max_moves)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m go_env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m players \u001b[39m=\u001b[39m [model1, model2]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(max_moves):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mif\u001b[39;00m go_env\u001b[39m.\u001b[39mdone: \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m players:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'OrderEnforcing' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "def play_tournament(wins, draws, games_played, b_w):\n",
    "    # print(\"Starting a tournament\")\n",
    "    # start1 = time.time()\n",
    "    for player1_index in range(len(players)):\n",
    "        for player2_index in range(len(players)):\n",
    "            if player1_index == player2_index: continue\n",
    "            games_played[player1_index] += 1\n",
    "            games_played[player2_index] += 1\n",
    "            p1, p2 = players[player1_index], players[player2_index]\n",
    "            # print(f\"  Starting a game between {player1_index} and {player2_index}\", end=\"\")\n",
    "            # start = time.time()\n",
    "            go_env = play_model_vs_model_no_render(p1, p2, gym.make('gym_go:go-v0', size=BOARD_SIZE, komi=0, reward_method='heuristic'))\n",
    "            # stop = time.time()\n",
    "            if go_env.reward() > 0:\n",
    "                wins[player1_index] += 1\n",
    "                b_w[0] += 1\n",
    "            elif go_env.reward() < 0:\n",
    "                wins[player2_index] += 1\n",
    "                b_w[1] += 1\n",
    "            else:\n",
    "                draws[player1_index] += 1\n",
    "                draws[player2_index] += 1\n",
    "            # print(f\", reward: {go_env.reward()}, time: {stop-start} sec\")\n",
    "    # stop1 = time.time()\n",
    "    # print(f\"Tournament took {stop1-start1}\")\n",
    "b_w = [0]*2\n",
    "wins, draws, games_played = [0]*len(players), [0]*len(players), [0]*len(players)\n",
    "# Parallel(n_jobs=10)(delayed(play_tournament)(wins, draws, games_played, b_w) for _ in range(1000))\n",
    "for game_number in range(1000):\n",
    "    print(\"Tournament: \", game_number, end=\"\\r\")\n",
    "    play_tournament(wins, draws, games_played, b_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2000]\n",
      "[400, 400, 400, 400, 400]\n",
      "[800, 800, 800, 800, 800]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(b_w)\n",
    "print(wins)\n",
    "print(games_played)\n",
    "print(draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\n",
    "mcts.run(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcts.root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('ml2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcb4a11841b46872ee11df9ca1f43eeee065535876db12c9a82fb397caea1117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
