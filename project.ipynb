{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore deprecation warnings ('safe' as long as we don't update packages)\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "from math import sqrt, log, inf\n",
    "import copy\n",
    "\n",
    "import gym\n",
    "from gym_go.gogame import turn, random_weighted_action, random_action\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCB_C = 2\n",
    "\n",
    "# Board will be a BOARD_SIZE * BOARD_SIZE board (BOARD_SIZE**2)\n",
    "BOARD_SIZE = 5\n",
    "ACTIONSPACE_LENGTH = BOARD_SIZE ** 2 + 1\n",
    "'''\n",
    "The state object that is returned by the reset and step functions of the environment is a\n",
    "6 x BOARD_SIZE x BOARD_SIZE numpy array. All values in the array are either 0 or 1.\n",
    "'''\n",
    "\n",
    "# 0 - Black pieces\n",
    "# 1 - White pieces\n",
    "# 2 - Turn (0 - black, 1 - white)\n",
    "# 3 - Invalid moves (including ko-protection)\n",
    "# 4 - Previous move was a pass\n",
    "# 5 - Game over\n",
    "BLACK, WHITE, INVALID = 0, 1, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search\n",
    "\n",
    "1. Selection\n",
    "    - Taverse the tree to find greatest UCB-score\n",
    "2. Expansion\n",
    "    - If the selected leaf node has been visited before expand by adding weighted game action\n",
    "3. Rollout\n",
    "    - Simulate the game until end-condition from the expanded leaf\n",
    "4. Back-propagation\n",
    "    - Updating the value of each ancestor node of the expanded leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, env, parent, action):\n",
    "        self.env : gym.Env = env # This env will be altered by the other player\n",
    "        self.value : int = 0 # Value estimate\n",
    "        self.trials : int = 0 # Number of trials for this node\n",
    "        self.parent : Node = parent # Parent node of this node\n",
    "        self.children : list[Node] = [] # List of children of this node\n",
    "        self.action : int = action # The step action made by this node\n",
    "    \n",
    "    # calculate a Upper Confidence Bound\n",
    "    def ucb(self, total_trials):\n",
    "        return self.value + ( UCB_C * sqrt(log(total_trials) / self.trials) )\n",
    "    \n",
    "    # Add a new node to a leaf node\n",
    "    def expansion(self):\n",
    "        for action in range(ACTIONSPACE_LENGTH - 1):\n",
    "            x, y = action // BOARD_SIZE, action % BOARD_SIZE\n",
    "            if self.env.state()[INVALID, x, y] == 0:\n",
    "                child_env = copy.deepcopy(self.env)\n",
    "                child_env.step(action)\n",
    "                self.children.append(Node(child_env, self, action))\n",
    "\n",
    "        child_env = copy.deepcopy(self.env)\n",
    "        child_env.step(ACTIONSPACE_LENGTH - 1)       \n",
    "        self.children.append(Node(child_env, self, ACTIONSPACE_LENGTH - 1))\n",
    "\n",
    "    # Simulate game from current move until end-condition returning the score\n",
    "    def rollout(self, move_selection_method):\n",
    "        if self.env.done:\n",
    "            return self.env.reward()\n",
    "        \n",
    "        rollout_env = copy.deepcopy(self.env)\n",
    "        rollout_result = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            random_action = move_selection_method(rollout_env)\n",
    "            _, reward, done, _ = rollout_env.step(random_action)\n",
    "            rollout_result += reward\n",
    "        return rollout_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monte_Carlo_Tree_Search():\n",
    "    def __init__(self, size, ml_model):\n",
    "        self.env : gym.Env = gym.make('gym_go:go-v0', size=size, reward_method='heuristic')\n",
    "        self.env.reset()\n",
    "        self.root = Node(self.env, None, None)\n",
    "        self.ml_model = ml_model\n",
    "        ml_model.to(device)\n",
    "    \n",
    "    # Gets the weights of all moves from the Machine Learning model\n",
    "    def __get_move_weights(self, env : gym.Env):\n",
    "        state = env.state()\n",
    "        if self.ml_model is not None:\n",
    "            move_weights = self.ml_model.forward(torch.tensor(state, device=device)).cpu().detach().numpy()\n",
    "        else:\n",
    "            move_weights = np.ones(ACTIONSPACE_LENGTH)\n",
    "\n",
    "        board_shape = state.shape[1:]\n",
    "        for i in range(len(move_weights) - 1):\n",
    "            action2d = i // board_shape[0], i % board_shape[1], i\n",
    "            if state[INVALID, action2d[0], action2d[1]] == 1:\n",
    "                move_weights[i] = 0.0\n",
    "        return move_weights\n",
    "\n",
    "    # Gets a weighted move for the given env\n",
    "    def get_weighted_move(self, env : gym.Env):\n",
    "        move_weights = self.__get_move_weights(env)\n",
    "        return random_weighted_action(move_weights)\n",
    "\n",
    "    # Update scores of all parent nodes after rollout\n",
    "    def __back_propagation(self, rollout_node: Node, rollout_result):\n",
    "        current_node = rollout_node\n",
    "        while current_node != None:\n",
    "            current_node.trials += 1\n",
    "            if turn(self.env.state()) == BLACK:\n",
    "                current_node.value -= rollout_result\n",
    "            if turn(self.env.state()) == WHITE:                \n",
    "                current_node.value += rollout_result\n",
    "            current_node = current_node.parent\n",
    "    \n",
    "    # Find and return the leaf node with the highest UCB-score \n",
    "    def __selection(self, node: Node = None):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        selected_child = node\n",
    "        current_node = node\n",
    "        while len(current_node.children) > 0:\n",
    "            current_best_ucb = -inf\n",
    "            for child in current_node.children:\n",
    "                if child.trials == 0:\n",
    "                    return child\n",
    "\n",
    "                child_ucb = child.ucb(self.root.trials)\n",
    "\n",
    "                if child_ucb > current_best_ucb:\n",
    "                    selected_child = child\n",
    "                    current_best_ucb = child_ucb\n",
    "\n",
    "            current_node = selected_child\n",
    "\n",
    "        return selected_child\n",
    "    \n",
    "    # Explores the tree for the given number of iterations\n",
    "    def run(self, iterations, node: Node = None):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "\n",
    "        selected_node = node\n",
    "        run = 0\n",
    "        while run < iterations:\n",
    "            selected_node = self.__selection(node)\n",
    "\n",
    "            if not selected_node.env.done and selected_node.trials > 0:\n",
    "                selected_node.expansion()\n",
    "                selected_node = selected_node.children[0]\n",
    "\n",
    "            rollout_result = selected_node.rollout(self.get_weighted_move)\n",
    "            \n",
    "            self.__back_propagation(selected_node, rollout_result)\n",
    "            run += 1\n",
    "\n",
    "    # Explores plays one game\n",
    "    def run_game(self):\n",
    "        # Run MCTS until a game is completed\n",
    "        selected_node = self.root\n",
    "        run = 1\n",
    "        while not selected_node.env.done:\n",
    "            # print(\"run:\", run)\n",
    "            selected_node = self.__selection()\n",
    "\n",
    "            if selected_node.trials > 0:\n",
    "                # print(\"Expanding node\")\n",
    "                selected_node.expansion()\n",
    "                selected_node = selected_node.children[0]\n",
    "\n",
    "            # print(\"Rollout\")\n",
    "            rollout_result = selected_node.rollout(self.get_weighted_move)\n",
    "            self.__back_propagation(selected_node, rollout_result)\n",
    "            # print(\"Done:\", selected_node.env.done)\n",
    "            run += 1\n",
    "        # returns the node to allow for printing the game\n",
    "        return selected_node\n",
    "    \n",
    "    # searches the tree for a spesific state\n",
    "    def __find_node_from_state(self, state, node: Node = None):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        if np.array_equal(node.env.state(), state):\n",
    "            return node\n",
    "\n",
    "        for child in node.children:\n",
    "            if np.array_equal(child.env.state(), state):\n",
    "                return child\n",
    "            \n",
    "            res = self.__find_node_from_state(state, child)\n",
    "            if res != None and np.array_equal(res.env.state(), state):\n",
    "                return res\n",
    "\n",
    "    # Attempts to find the best move from the tree by searching for the state and finding the best child for that state\n",
    "    def get_move_from_env(self, env):\n",
    "        node = self.__find_node_from_state(env.state())\n",
    "\n",
    "        while node is None:\n",
    "            self.run(15)\n",
    "            node = self.__find_node_from_state(env.state())\n",
    "\n",
    "        self.run(15, node)\n",
    "\n",
    "        best_child = None\n",
    "        current_best_value = -inf\n",
    "        for child in node.children:\n",
    "            if child.value > current_best_value:\n",
    "                best_child = child\n",
    "                current_best_value = child.value\n",
    "\n",
    "        if best_child != None:\n",
    "            if len(best_child.children) == 0 and not best_child.env.done:\n",
    "                best_child.expansion()\n",
    "            return best_child\n",
    "\n",
    "    # Makes a list of all states and a list of all move_weights for all expanded nodes in the tree\n",
    "    def get_tree_data(self):\n",
    "        x, y = [], []\n",
    "        self.__get_node_data(self.root, x, y)\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "    # recurrsive tree traversal method for get_tree_data\n",
    "    def __get_node_data(self, node, x, y):\n",
    "        x.append(node.env.state())\n",
    "        y.append([0] * (BOARD_SIZE**2 + 1))\n",
    "        for child in node.children:\n",
    "            y[-1][child.action] = child.value\n",
    "            if len(child.children) > 0:\n",
    "                self.__get_node_data(child, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game_no_render(mcts : Monte_Carlo_Tree_Search, go_env: gym.Env):\n",
    "    go_env.reset()\n",
    "    done = go_env.done\n",
    "    turn_nr = 0\n",
    "    while not done:\n",
    "        action = random_action(go_env.state())\n",
    "        _, _, done, _ = go_env.step(action)\n",
    "\n",
    "        if done:\n",
    "            continue\n",
    "\n",
    "        node = mcts.get_move_from_env(go_env)\n",
    "        _, _, done, _ = go_env.step(node.action)\n",
    "        turn_nr += 1\n",
    "        if turn_nr > 300:\n",
    "            break\n",
    "    \n",
    "    return go_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erik\\miniconda3\\envs\\ml-project\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\erik\\miniconda3\\envs\\ml-project\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mcts_test \u001b[39m=\u001b[39m Monte_Carlo_Tree_Search(BOARD_SIZE, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m _ \u001b[39m=\u001b[39m mcts_test\u001b[39m.\u001b[39;49mrun_game()\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 9\u001b[0m in \u001b[0;36mMonte_Carlo_Tree_Search.run_game\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     selected_node \u001b[39m=\u001b[39m selected_node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# print(\"Rollout\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m rollout_result \u001b[39m=\u001b[39m selected_node\u001b[39m.\u001b[39;49mrollout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_weighted_move)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__back_propagation(selected_node, rollout_result)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# print(\"Done:\", selected_node.env.done)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 9\u001b[0m in \u001b[0;36mNode.rollout\u001b[1;34m(self, move_selection_method)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     random_action \u001b[39m=\u001b[39m move_selection_method(rollout_env)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     _, reward, done, _ \u001b[39m=\u001b[39m rollout_env\u001b[39m.\u001b[39;49mstep(random_action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     rollout_result \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rollout_result\n",
      "File \u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml-project\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml-project\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\users\\erik\\gymgo\\gym_go\\envs\\go_env.py:64\u001b[0m, in \u001b[0;36mGoEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_ \u001b[39m=\u001b[39m gogame\u001b[39m.\u001b[39mnext_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_, action, canonical\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone \u001b[39m=\u001b[39m gogame\u001b[39m.\u001b[39mgame_ended(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_)\n\u001b[1;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreward(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo()\n",
      "File \u001b[1;32mc:\\users\\erik\\gymgo\\gym_go\\envs\\go_env.py:142\u001b[0m, in \u001b[0;36mGoEnv.reward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwinner()\n\u001b[0;32m    141\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_method \u001b[39m==\u001b[39m RewardMethod\u001b[39m.\u001b[39mHEURISTIC:\n\u001b[1;32m--> 142\u001b[0m     black_area, white_area \u001b[39m=\u001b[39m gogame\u001b[39m.\u001b[39;49mareas(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate_)\n\u001b[0;32m    143\u001b[0m     area_difference \u001b[39m=\u001b[39m black_area \u001b[39m-\u001b[39m white_area\n\u001b[0;32m    144\u001b[0m     komi_correction \u001b[39m=\u001b[39m area_difference \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkomi\n",
      "File \u001b[1;32mc:\\users\\erik\\gymgo\\gym_go\\gogame.py:288\u001b[0m, in \u001b[0;36mareas\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_empty_areas \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    287\u001b[0m     empty_area \u001b[39m=\u001b[39m empty_labels \u001b[39m==\u001b[39m label\n\u001b[1;32m--> 288\u001b[0m     neighbors \u001b[39m=\u001b[39m ndimage\u001b[39m.\u001b[39;49mbinary_dilation(empty_area)\n\u001b[0;32m    289\u001b[0m     black_claim \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     white_claim \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml-project\\lib\\site-packages\\scipy\\ndimage\\_morphology.py:507\u001b[0m, in \u001b[0;36mbinary_dilation\u001b[1;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(\u001b[39minput\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m structure \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 507\u001b[0m     structure \u001b[39m=\u001b[39m generate_binary_structure(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mndim, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    508\u001b[0m origin \u001b[39m=\u001b[39m _ni_support\u001b[39m.\u001b[39m_normalize_sequence(origin, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mndim)\n\u001b[0;32m    509\u001b[0m structure \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(structure)\n",
      "File \u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml-project\\lib\\site-packages\\scipy\\ndimage\\_morphology.py:210\u001b[0m, in \u001b[0;36mgenerate_binary_structure\u001b[1;34m(rank, connectivity)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39marray(\u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m--> 210\u001b[0m output \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mfabs(numpy\u001b[39m.\u001b[39;49mindices([\u001b[39m3\u001b[39;49m] \u001b[39m*\u001b[39;49m rank) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    211\u001b[0m output \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39madd\u001b[39m.\u001b[39mreduce(output, \u001b[39m0\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m connectivity\n",
      "File \u001b[1;32mc:\\Users\\erik\\miniconda3\\envs\\ml-project\\lib\\site-packages\\numpy\\core\\numeric.py:1785\u001b[0m, in \u001b[0;36mindices\u001b[1;34m(dimensions, dtype, sparse)\u001b[0m\n\u001b[0;32m   1783\u001b[0m         res \u001b[39m=\u001b[39m res \u001b[39m+\u001b[39m (idx,)\n\u001b[0;32m   1784\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1785\u001b[0m         res[i] \u001b[39m=\u001b[39m idx\n\u001b[0;32m   1786\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mcts_test = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\n",
    "_ = mcts_test.run_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n",
      "White won!\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    env = play_game_no_render(mcts_test, copy.deepcopy(mcts_test.env))\n",
    "    if not env.done:\n",
    "        print(\"Game stopped after 300 turns: \\nIt was resigned and is a draw.\")\n",
    "        continue\n",
    "        \n",
    "    if env.reward() < 0:\n",
    "        print(\"White won!\")\n",
    "    if env.reward() > 0:\n",
    "        print(\"Black won!\")\n",
    "    if env.reward() == 0:\n",
    "        print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(6, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = x.to(device)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 0, -1)\n",
    "        x = F.softmax(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def avg_accuracy(self, x, y):\n",
    "        avg = 0\n",
    "        for i in range(len(x)):\n",
    "            avg += torch.mean(torch.eq(self.forward(x[i]).argmax(), y[i].argmax()).float())\n",
    "        return (avg/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility methods for importing and exporting models, defined outside class\n",
    "def export_model(cnn, name=\"cnn\"):\n",
    "    torch.save(cnn.state_dict(), \"cnns/\" + name + \".pth\")\n",
    "\n",
    "def import_model(cnn, name=\"cnn\"):\n",
    "    cnn.load_state_dict(torch.load(\"cnns/\" + name + \".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lr, momentum):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    model.to(device)\n",
    "    for epoch in range(10):\n",
    "        mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model) # new tree\n",
    "        mcts.run_game() # run a single game to completion\n",
    "        x, y = mcts.get_tree_data() # get data\n",
    "        running_loss = .0 \n",
    "        for i in range(len(x)):\n",
    "            inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "            labels = F.softmax(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 10 == 9:\n",
    "                print(f'[{epoch:3d}, {i + 1:3d}] loss: {running_loss / 10:.5f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "import time\n",
    "\n",
    "def train(n_games=1000):\n",
    "    model = CNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # Stats\n",
    "    all_x, all_y, loss_values, acc_values = [], [], [], []\n",
    "    total_time = 0\n",
    "\n",
    "    # Simulate N games\n",
    "    for _ in range(n_games):\n",
    "\n",
    "        # Run a simulation and time it for statistics\n",
    "        mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model)\n",
    "        start = time.time()\n",
    "        mcts.run_game()\n",
    "        stop = time.time()\n",
    "        total_time += (stop - start)\n",
    "\n",
    "        game_loss = .0\n",
    "\n",
    "        # Train model on data\n",
    "        x, y = mcts.get_tree_data()\n",
    "        for i in range(len(x)):\n",
    "            inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "            labels = F.softmax(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            game_loss += loss.item()\n",
    "            \n",
    "            # Add data to master list for accuracy calculation\n",
    "            all_x.append(x[i])\n",
    "            all_y.append(y[i])\n",
    "        \n",
    "        # After training, check accuracy against previous data\n",
    "        acc_values.append(model.avg_accuracy(all_x, all_y).item())\n",
    "        loss_values.append(game_loss/len(x))\n",
    "\n",
    "    print(f'''Finished running {n_games} games\n",
    "    Time..............: {total_time}\n",
    "    Avg. time per game: {total_time/n_games}''')\n",
    "    return model, loss_values, acc_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 5 games\n",
      "    Time..............: 100.0963933467865\n",
      "    Avg. time per game: 20.0192786693573\n"
     ]
    }
   ],
   "source": [
    "model, loss_values, acc_values = train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2582946053698802, 3.2574012619849304, 3.258281778419517, 3.2538124084473785, 3.255536508039775]\n",
      "[0.0714285746216774, 0.16250000894069672, 0.15294118225574493, 0.1666666716337204, 0.17293234169483185]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x237b4972280>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loss_values)\n",
    "print(acc_values)\n",
    "\n",
    "# plt.plot(loss_values)\n",
    "plt.plot(acc_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS and CNN combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an MCTS\n",
    "2. Generate a lot of data from the MCTS\n",
    "3. Use the data to train a CNN\n",
    "4. Use the CNN in a new MCTS to hopefully make the MCTS make better choices\n",
    "5. Generate new data with the new MCTS\n",
    "6. Train a new CNN... repeat ad infinitum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 93 datapoints\n",
      "[  0,    5] loss: 3.258\n",
      "[  0,   10] loss: 3.258\n",
      "[  0,   15] loss: 3.260\n",
      "[  0,   20] loss: 3.258\n",
      "[  0,   25] loss: 3.257\n",
      "[  0,   30] loss: 3.261\n",
      "[  0,   35] loss: 3.256\n",
      "[  0,   40] loss: 3.258\n",
      "[  0,   45] loss: 3.256\n",
      "[  0,   50] loss: 3.256\n",
      "[  0,   55] loss: 3.256\n",
      "[  0,   60] loss: 3.258\n",
      "[  0,   65] loss: 3.257\n",
      "[  0,   70] loss: 3.258\n",
      "[  0,   75] loss: 3.257\n",
      "[  0,   80] loss: 3.259\n",
      "[  0,   85] loss: 3.261\n",
      "[  0,   90] loss: 3.258\n",
      "Training on 15 datapoints\n",
      "[  1,    5] loss: 3.258\n",
      "[  1,   10] loss: 3.257\n",
      "[  1,   15] loss: 3.257\n",
      "Training on 63 datapoints\n",
      "[  2,    5] loss: 3.258\n",
      "[  2,   10] loss: 3.257\n",
      "[  2,   15] loss: 3.256\n",
      "[  2,   20] loss: 3.257\n",
      "[  2,   25] loss: 3.255\n",
      "[  2,   30] loss: 3.257\n",
      "[  2,   35] loss: 3.259\n",
      "[  2,   40] loss: 3.256\n",
      "[  2,   45] loss: 3.256\n",
      "[  2,   50] loss: 3.259\n",
      "[  2,   55] loss: 3.256\n",
      "[  2,   60] loss: 3.255\n",
      "Training on 25 datapoints\n",
      "[  3,    5] loss: 3.255\n",
      "[  3,   10] loss: 3.254\n",
      "[  3,   15] loss: 3.259\n",
      "[  3,   20] loss: 3.258\n",
      "[  3,   25] loss: 3.255\n",
      "Training on 82 datapoints\n",
      "[  4,    5] loss: 3.255\n",
      "[  4,   10] loss: 3.255\n",
      "[  4,   15] loss: 3.255\n",
      "[  4,   20] loss: 3.256\n",
      "[  4,   25] loss: 3.260\n",
      "[  4,   30] loss: 3.259\n",
      "[  4,   35] loss: 3.250\n",
      "[  4,   40] loss: 3.259\n",
      "[  4,   45] loss: 3.259\n",
      "[  4,   50] loss: 3.256\n",
      "[  4,   55] loss: 3.257\n",
      "[  4,   60] loss: 3.256\n",
      "[  4,   65] loss: 3.248\n",
      "[  4,   70] loss: 3.248\n",
      "[  4,   75] loss: 3.250\n",
      "[  4,   80] loss: 3.259\n",
      "Training on 54 datapoints\n",
      "[  5,    5] loss: 3.244\n",
      "[  5,   10] loss: 3.247\n",
      "[  5,   15] loss: 3.254\n",
      "[  5,   20] loss: 3.261\n",
      "[  5,   25] loss: 3.256\n",
      "[  5,   30] loss: 3.260\n",
      "[  5,   35] loss: 3.259\n",
      "[  5,   40] loss: 3.252\n",
      "[  5,   45] loss: 3.255\n",
      "[  5,   50] loss: 3.255\n",
      "Training on 23 datapoints\n",
      "[  6,    5] loss: 3.251\n",
      "[  6,   10] loss: 3.261\n",
      "[  6,   15] loss: 3.252\n",
      "[  6,   20] loss: 3.250\n",
      "Training on 119 datapoints\n",
      "[  7,    5] loss: 3.258\n",
      "[  7,   10] loss: 3.260\n",
      "[  7,   15] loss: 3.257\n",
      "[  7,   20] loss: 3.243\n",
      "[  7,   25] loss: 3.243\n",
      "[  7,   30] loss: 3.240\n",
      "[  7,   35] loss: 3.229\n",
      "[  7,   40] loss: 3.243\n",
      "[  7,   45] loss: 3.258\n",
      "[  7,   50] loss: 3.265\n",
      "[  7,   55] loss: 3.258\n",
      "[  7,   60] loss: 3.269\n",
      "[  7,   65] loss: 3.254\n",
      "[  7,   70] loss: 3.245\n",
      "[  7,   75] loss: 3.226\n",
      "[  7,   80] loss: 3.234\n",
      "[  7,   85] loss: 3.256\n",
      "[  7,   90] loss: 3.265\n",
      "[  7,   95] loss: 3.185\n",
      "[  7,  100] loss: 3.219\n",
      "[  7,  105] loss: 3.153\n",
      "[  7,  110] loss: 3.263\n",
      "[  7,  115] loss: 3.263\n",
      "Training on 64 datapoints\n",
      "[  8,    5] loss: 3.258\n",
      "[  8,   10] loss: 3.288\n",
      "[  8,   15] loss: 3.269\n",
      "[  8,   20] loss: 3.172\n",
      "[  8,   25] loss: 2.906\n",
      "[  8,   30] loss: 3.134\n",
      "[  8,   35] loss: 3.238\n",
      "[  8,   40] loss: 2.970\n",
      "[  8,   45] loss: 3.286\n",
      "[  8,   50] loss: 3.116\n",
      "[  8,   55] loss: 3.006\n",
      "[  8,   60] loss: 3.315\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cnn \u001b[39m=\u001b[39m CNN()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# mcts.run(1000)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# x, y = mcts.get_tree_data()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#     loss.backward()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#     optimizer.step()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m train_model(cnn, \u001b[39m.01\u001b[39;49m, \u001b[39m.9\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 18\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, lr, momentum)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     mcts \u001b[39m=\u001b[39m Monte_Carlo_Tree_Search(BOARD_SIZE, model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     mcts\u001b[39m.\u001b[39;49mrun_game()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     x, y \u001b[39m=\u001b[39m mcts\u001b[39m.\u001b[39mget_tree_data()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     running_loss \u001b[39m=\u001b[39m \u001b[39m.0\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 18\u001b[0m in \u001b[0;36mMonte_Carlo_Tree_Search.run_game\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     selected_node \u001b[39m=\u001b[39m selected_node\u001b[39m.\u001b[39mchildren[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# print(\"Rollout\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m rollout_result \u001b[39m=\u001b[39m selected_node\u001b[39m.\u001b[39;49mrollout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_weighted_move)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__back_propagation(selected_node, rollout_result)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# print(\"Done:\", selected_node.env.done)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 18\u001b[0m in \u001b[0;36mNode.rollout\u001b[1;34m(self, move_selection_method)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     random_action \u001b[39m=\u001b[39m move_selection_method(rollout_env)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     _, reward, done, _ \u001b[39m=\u001b[39m rollout_env\u001b[39m.\u001b[39mstep(random_action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     rollout_result \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n",
      "\u001b[1;32mc:\\Users\\erik\\dev\\ml-project\\project.ipynb Cell 18\u001b[0m in \u001b[0;36mMonte_Carlo_Tree_Search.get_weighted_move\u001b[1;34m(self, env)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_weighted_move\u001b[39m(\u001b[39mself\u001b[39m, env : gym\u001b[39m.\u001b[39mEnv):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     move_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_move_weights(env)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erik/dev/ml-project/project.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m random_weighted_action(move_weights)\n",
      "File \u001b[1;32mc:\\users\\erik\\gymgo\\gym_go\\gogame.py:392\u001b[0m, in \u001b[0;36mrandom_weighted_action\u001b[1;34m(move_weights)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[39mAssumes all invalid moves have weight 0\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mAction is 1D\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39mExpected shape is (NUM OF MOVES, )\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    391\u001b[0m move_weights \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mnormalize(move_weights[np\u001b[39m.\u001b[39mnewaxis], norm\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 392\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(np\u001b[39m.\u001b[39;49marange(\u001b[39mlen\u001b[39;49m(move_weights[\u001b[39m0\u001b[39;49m])), p\u001b[39m=\u001b[39;49mmove_weights[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mmtrand.pyx:939\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "# mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\n",
    "# mcts.run(1000)\n",
    "# x, y = mcts.get_tree_data()\n",
    "# print(\"Datapoints: \", len(x))\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)\n",
    "# cnn.to(device)\n",
    "# for i in range(len(x)):\n",
    "#     inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "#     labels = F.softmax(labels)\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = cnn(inputs)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# train_model(cnn, .01, .9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "554e4e9be84610b8cfdc647d12e0c13356c189fbf7b6128724357bba0c0ac4f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
