{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Factor out classes into .py-files to make notebook more concise\n",
    "- Find package versions where we don't need to filter warnings (older packages)\n",
    "- Set up pseudocode for the tournament;\n",
    "    - players, saving models, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore deprecation warnings ('safe' as long as we don't update packages)\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.CNN import CNN\n",
    "from src.MCTS import Monte_Carlo_Tree_Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BOARD_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def play_game_no_render(mcts : Monte_Carlo_Tree_Search, go_env: gym.Env):\n",
    "#     go_env.reset()\n",
    "#     done = go_env.done\n",
    "#     turn_nr = 0\n",
    "#     while not done:\n",
    "#         action = random_action(go_env.state())\n",
    "#         _, _, done, _ = go_env.step(action)\n",
    "\n",
    "#         if done:\n",
    "#             continue\n",
    "\n",
    "#         node = mcts.get_move_from_env(go_env)\n",
    "#         _, _, done, _ = go_env.step(node.action)\n",
    "#         turn_nr += 1\n",
    "#         if turn_nr > 300:\n",
    "#             break\n",
    "    \n",
    "#     return go_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcts_test = Monte_Carlo_Tree_Search(BOARD_SIZE, None)\n",
    "# _ = mcts_test.run_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     env = play_game_no_render(mcts_test, copy.deepcopy(mcts_test.env))\n",
    "#     if not env.done:\n",
    "#         print(\"Game stopped after 300 turns: \\nIt was resigned and is a draw.\")\n",
    "#         continue\n",
    "        \n",
    "#     if env.reward() < 0:\n",
    "#         print(\"White won!\")\n",
    "#     if env.reward() > 0:\n",
    "#         print(\"Black won!\")\n",
    "#     if env.reward() == 0:\n",
    "#         print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, lr, momentum):\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     for epoch in range(10):\n",
    "#         mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model) # new tree\n",
    "#         mcts.run_game() # run a single game to completion\n",
    "#         x, y = mcts.get_tree_data() # get data\n",
    "#         running_loss = .0 \n",
    "#         for i in range(len(x)):\n",
    "#             inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "#             labels = F.softmax(labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item()\n",
    "\n",
    "#             if i % 10 == 9:\n",
    "#                 print(f'[{epoch:3d}, {i + 1:3d}] loss: {running_loss / 10:.5f}')\n",
    "#                 running_loss = 0.0\n",
    "\n",
    "# def train(n_games=1000):\n",
    "\n",
    "#     model = CNN()\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#     all_x, all_y = [], []\n",
    "\n",
    "#     # Simulate N games\n",
    "#     for _ in range(n_games):\n",
    "#         mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model)\n",
    "#         mcts.run(10_000)\n",
    "#         x, y = mcts.get_tree_data()\n",
    "\n",
    "#         for i in range(len(x)):\n",
    "#             inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "#             labels = F.softmax(labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             all_x.append(x[i])\n",
    "#             all_y.append(y[i])\n",
    "        \n",
    "#         # After training, check accuracy against previous data\n",
    "#         acc_values.append(model.avg_accuracy(all_x, all_y).item())\n",
    "#         loss_values.append(game_loss/len(x))\n",
    "\n",
    "#     print(f'''Finished running {n_games} games\n",
    "#     Time..............: {total_time}\n",
    "#     Avg. time per game: {total_time/n_games}''')\n",
    "#     return model, loss_values, acc_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss_values, acc_values = train(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS and CNN combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_game(x, y, model):\n",
    "    mcts = Monte_Carlo_Tree_Search(BOARD_SIZE, model)\n",
    "    mcts.run_game()\n",
    "    # mcts.run(10_000)\n",
    "    a, b = mcts.get_tree_data()\n",
    "    x.append(a)\n",
    "    y.append(b)\n",
    "\n",
    "def generate_games(x, y, n_games, model):\n",
    "    print(f\"Generating {n_games} games\")\n",
    "    Parallel(n_jobs=10)(delayed(generate_game)(x, y, model) for _ in range(1, n_games))\n",
    "\n",
    "def train_model(model, criterion, optimizer, x, y):\n",
    "    print(\"Training model\")\n",
    "    for i in range(len(x)):\n",
    "        inputs, labels = torch.tensor(x[i], device=device), torch.tensor(y[i], device=device)\n",
    "        labels = F.softmax(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "generate_games(x, y, 1000, None)\n",
    "\n",
    "model = CNN()\n",
    "model.to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train_model(model, criterion, optimizer, x, y)\n",
    "\n",
    "print(\"Exporting model\")\n",
    "torch.save(model.state_dict(), f\"models/only-mcts.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000 games\n",
      "Training model\n",
      "Generating 1000 games\n",
      "Training model\n",
      "Generating 1000 games\n",
      "Training model\n",
      "Generating 1000 games\n",
      "Training model\n"
     ]
    }
   ],
   "source": [
    "# model = CNN()\n",
    "# model.load_state_dict(torch.load(\"models/only-mcts.pth\"))\n",
    "# model.eval()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "for i in range(2, 6):\n",
    "    x, y = [], []\n",
    "    generate_games(x, y, 1000, model)\n",
    "    train_model(model, criterion, optimizer, x, y)\n",
    "    torch.save(model.state_dict(), f\"models/{i}-times.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "554e4e9be84610b8cfdc647d12e0c13356c189fbf7b6128724357bba0c0ac4f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
