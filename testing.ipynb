{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gym, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from src.CNN import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(black_player=None, white_player=None, max_moves=300):\n",
    "    go_env = gym.make('gym_go:go-v0', size=5, komi=0, reward_method='heuristic')\n",
    "    go_env.reset()\n",
    "\n",
    "    if black_player and white_player:\n",
    "        go_env.step(go_env.uniform_random_action())\n",
    "        go_env.step(go_env.uniform_random_action())\n",
    "\n",
    "    for _ in range(max_moves):\n",
    "        # Player 1's turn\n",
    "        if go_env.done: break\n",
    "        if black_player: \n",
    "            moves = black_player.forward(go_env.state()).detach().cpu().numpy() * go_env.valid_moves()\n",
    "            go_env.step(moves.argmax())\n",
    "        else: go_env.step(go_env.uniform_random_action())\n",
    "\n",
    "        # Player 2's turn\n",
    "        if go_env.done: break\n",
    "        if white_player: \n",
    "            moves = white_player.forward(go_env.state()).detach().cpu().numpy() * go_env.valid_moves()\n",
    "            go_env.step(moves.argmax())\n",
    "        else: go_env.step(go_env.uniform_random_action())\n",
    "    return go_env.reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_percent(black_player=None, white_player=None, n_games=1000, max_moves=300):\n",
    "    black, white, draws = 0, 0, 0\n",
    "    results = Parallel(n_jobs=6)(delayed(play_game)(black_player, white_player, max_moves) for _ in range(n_games))\n",
    "    for i in range(n_games):\n",
    "        res = results[i]\n",
    "        if res > 0: black += 1\n",
    "        elif res < 0: white += 1\n",
    "        else: draws += 1\n",
    "    return (black/n_games)*100, (white/n_games)*100, (draws/n_games)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(5):\n",
    "    model = CNN()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(f\"src/models/1000-games/{i}-times.pth\"))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0:\n",
      "  0: b=46.71%, w=51.50%, d=1.80%, took 7.09 seconds\n",
      "  1: b=48.50%, w=49.70%, d=1.80%, took 6.27 seconds\n",
      "  2: b=40.72%, w=59.28%, d=0.00%, took 7.28 seconds\n",
      "  3: b=41.32%, w=55.69%, d=2.99%, took 7.43 seconds\n",
      "  4: b=37.13%, w=59.88%, d=2.99%, took 9.83 seconds\n",
      "Model 1:\n",
      "  0: b=43.71%, w=56.29%, d=0.00%, took 6.35 seconds\n",
      "  1: b=32.93%, w=63.47%, d=3.59%, took 7.65 seconds\n",
      "  2: b=35.93%, w=61.08%, d=2.99%, took 8.17 seconds\n",
      "  3: b=38.92%, w=59.88%, d=1.20%, took 6.09 seconds\n",
      "  4: b=40.72%, w=58.08%, d=1.20%, took 8.26 seconds\n",
      "Model 2:\n",
      "  0: b=34.73%, w=65.27%, d=0.00%, took 7.93 seconds\n",
      "  1: b=38.32%, w=56.89%, d=4.79%, took 7.94 seconds\n",
      "  2: b=40.72%, w=58.68%, d=0.60%, took 6.55 seconds\n",
      "  3: b=38.92%, w=61.08%, d=0.00%, took 7.14 seconds\n",
      "  4: b=40.12%, w=57.49%, d=2.40%, took 7.82 seconds\n",
      "Model 3:\n",
      "  0: b=36.53%, w=59.88%, d=3.59%, took 7.74 seconds\n",
      "  1: b=37.72%, w=59.28%, d=2.99%, took 7.00 seconds\n",
      "  2: b=37.72%, w=60.48%, d=1.80%, took 8.79 seconds\n",
      "  3: b=32.93%, w=64.67%, d=2.40%, took 7.24 seconds\n",
      "  4: b=47.31%, w=50.90%, d=1.80%, took 7.45 seconds\n",
      "Model 4:\n",
      "  0: b=37.72%, w=61.68%, d=0.60%, took 7.73 seconds\n",
      "  1: b=37.13%, w=60.48%, d=2.40%, took 7.47 seconds\n",
      "  2: b=43.71%, w=55.09%, d=1.20%, took 7.81 seconds\n",
      "  3: b=34.13%, w=64.07%, d=1.80%, took 9.11 seconds\n",
      "  4: b=37.72%, w=59.88%, d=2.40%, took 8.05 seconds\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((5, 5), dtype=tuple)\n",
    "\n",
    "for black_index, black_player in enumerate(models):\n",
    "    print(f\"Model {black_index}:\")\n",
    "    for white_index, white_player in enumerate(models):\n",
    "        start = time.time()\n",
    "        (black, white, draw) = get_win_percent(black_player, white_player, 167)\n",
    "        stop = time.time()\n",
    "        results[black_index][white_index] = black, white, draw\n",
    "        print(f\"  {white_index}: b={black:2.2f}%, w={white:2.2f}%, d={draw:2.2f}%, took {stop-start:4.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41.31736526946108, 55.688622754491014, 2.9940119760479043)\n"
     ]
    }
   ],
   "source": [
    "print(results[0][3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ml-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c48e9d02fd8b77616e4eb406249914dfd12f6a6048a8be47690e9d71e734832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
